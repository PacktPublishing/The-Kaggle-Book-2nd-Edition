{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"037ace54361649edb8a32acaa900a258":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d95c0044c8487fb3d773cba424b303":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48f1f27028c344a98a3e92f27d212547":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"541a7017333d4afc918bd5be113bdb50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b350e80ad8a448b864c72817a89437a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_962389ad7dc2473fad406e39c30bf482","IPY_MODEL_b5ec0dbce26d4d17874515c3835f512a"],"layout":"IPY_MODEL_48f1f27028c344a98a3e92f27d212547"}},"5c7eb5f28ec04057a80310e577cc13b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_7e7233d032e549718a408edb2a836239","max":363423424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af2e9a3585c742f3a641c6b29e0bb1fd","value":363423424}},"6167234cfaa043cc9e7d489141dc31f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69a50fffddf7455e830aa06e9963e514":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a19f67385ec14652bdf0f53ff0c7d266","IPY_MODEL_f84d12ad59a84fb2b8f3aa36b1c270ab"],"layout":"IPY_MODEL_a5665dea0d7b4e86bc20ec043ddbe60c"}},"711aa437a78f4af68bf44875ba6124d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7233d032e549718a408edb2a836239":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962389ad7dc2473fad406e39c30bf482":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_711aa437a78f4af68bf44875ba6124d9","max":442,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f65ee2d9b58f4460a752c1b365bfce15","value":442}},"975a3eba5e1e42f3b7f53d1e8211f36a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c09bb56a9a7048f894f9340a1489a313","placeholder":"​","style":"IPY_MODEL_e778b61946b548948f152b1ef4bcd1c6","value":" 363M/363M [06:07&lt;00:00, 990kB/s]"}},"a19f67385ec14652bdf0f53ff0c7d266":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Downloading: 100%","description_tooltip":null,"layout":"IPY_MODEL_037ace54361649edb8a32acaa900a258","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d307474196274a419225128b3e6470cc","value":231508}},"a5665dea0d7b4e86bc20ec043ddbe60c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af2e9a3585c742f3a641c6b29e0bb1fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"b5ec0dbce26d4d17874515c3835f512a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12d95c0044c8487fb3d773cba424b303","placeholder":"​","style":"IPY_MODEL_cb0158ae479c4ec0a8c2bd20c73aa454","value":" 442/442 [00:03&lt;00:00, 126B/s]"}},"c09bb56a9a7048f894f9340a1489a313":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb0158ae479c4ec0a8c2bd20c73aa454":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d307474196274a419225128b3e6470cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"dfd9bd15b65b4b14b0885699611c9cbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c7eb5f28ec04057a80310e577cc13b8","IPY_MODEL_975a3eba5e1e42f3b7f53d1e8211f36a"],"layout":"IPY_MODEL_6167234cfaa043cc9e7d489141dc31f6"}},"e778b61946b548948f152b1ef4bcd1c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec254a4ffdd246ffaae5bbfc2cb95e51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f65ee2d9b58f4460a752c1b365bfce15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"f84d12ad59a84fb2b8f3aa36b1c270ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_541a7017333d4afc918bd5be113bdb50","placeholder":"​","style":"IPY_MODEL_ec254a4ffdd246ffaae5bbfc2cb95e51","value":" 232k/232k [00:00&lt;00:00, 308kB/s]"}}},"version_major":2,"version_minor":0}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":16295,"databundleVersionId":1099992,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras-preprocessing\n!pip install --upgrade scikit-learn scikeras\n!pip install \"protobuf<4.21.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:48:17.062902Z","iopub.execute_input":"2025-12-01T06:48:17.063108Z","iopub.status.idle":"2025-12-01T06:48:32.002072Z","shell.execute_reply.started":"2025-12-01T06:48:17.063090Z","shell.execute_reply":"2025-12-01T06:48:32.001375Z"}},"outputs":[{"name":"stdout","text":"Collecting keras-preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-preprocessing) (1.26.4)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras-preprocessing) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.9.1->keras-preprocessing) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.9.1->keras-preprocessing) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.9.1->keras-preprocessing) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.9.1->keras-preprocessing) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.9.1->keras-preprocessing) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.9.1->keras-preprocessing) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.9.1->keras-preprocessing) (2024.2.0)\nDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: keras-preprocessing\nSuccessfully installed keras-preprocessing-1.1.2\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nCollecting scikeras\n  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.16.0)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.0->scikit-learn) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->scikit-learn) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.0->scikit-learn) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.0->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.0->scikit-learn) (2024.2.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.0->scikit-learn) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\nDownloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\nInstalling collected packages: scikit-learn, scikeras\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.7.2\nCollecting protobuf<4.21.0\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport numpy as np\nnp.random.seed(0)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nfrom keras_preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\nfrom keras.layers import Input, Dense, LSTM, GRU, Embedding\nfrom keras.layers import Activation, Bidirectional, GlobalMaxPool1D, GlobalMaxPool2D, Dropout\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras_preprocessing import text, sequence\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import RMSprop, Adam\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nimport seaborn as sns\nimport transformers\nfrom transformers import AutoTokenizer\nfrom tokenizers import BertWordPieceTokenizer\nfrom keras.initializers import Constant\nfrom scikeras.wrappers import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\n\nstop=set(stopwords.words('english'))\n\nimport os\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-12-01T06:48:32.004151Z","iopub.execute_input":"2025-12-01T06:48:32.004395Z","iopub.status.idle":"2025-12-01T06:48:55.335208Z","shell.execute_reply.started":"2025-12-01T06:48:32.004370Z","shell.execute_reply":"2025-12-01T06:48:55.334621Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-12-01 06:48:33.621004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764571713.792995      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764571713.838940      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/shahules/complete-eda-baseline-model-0-708-lb\n\ndef basic_cleaning(text):\n    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n    text=re.sub(r'[^A-Za-z|\\s]','',text)\n    text=re.sub(r'\\*+','swear',text) #capture swear words that are **** out\n    return text\n\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\n# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef remove_multiplechars(text):\n    text = re.sub(r'(.)\\1{3,}',r'\\1', text)\n    return text\n\n\ndef clean(df):\n    for col in ['text']:#,'selected_text']:\n        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n        df[col]=df[col].astype(str).apply(lambda x:remove_emoji(x))\n        df[col]=df[col].astype(str).apply(lambda x:remove_html(x))\n        df[col]=df[col].astype(str).apply(lambda x:remove_multiplechars(x))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.335999Z","iopub.execute_input":"2025-12-01T06:48:55.336560Z","iopub.status.idle":"2025-12-01T06:48:55.342801Z","shell.execute_reply.started":"2025-12-01T06:48:55.336533Z","shell.execute_reply":"2025-12-01T06:48:55.342058Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=128):    \n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(length=maxlen)\n    all_ids = []\n    \n    for i in range(0, len(texts), chunk_size):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.343543Z","iopub.execute_input":"2025-12-01T06:48:55.343750Z","iopub.status.idle":"2025-12-01T06:48:55.394323Z","shell.execute_reply.started":"2025-12-01T06:48:55.343735Z","shell.execute_reply":"2025-12-01T06:48:55.393696Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def preprocess_news(df,stop=stop,n=1,col='text'):\n    '''Function to preprocess and create corpus'''\n    new_corpus=[]\n    stem=PorterStemmer()\n    lem=WordNetLemmatizer()\n    for text in df[col]:\n        words=[w for w in word_tokenize(text) if (w not in stop)]\n       \n        words=[lem.lemmatize(w) for w in words if(len(w)>n)]\n     \n        new_corpus.append(words)\n        \n    new_corpus=[word for l in new_corpus for word in l]\n    return new_corpus","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.395213Z","iopub.execute_input":"2025-12-01T06:48:55.395638Z","iopub.status.idle":"2025-12-01T06:48:55.407961Z","shell.execute_reply.started":"2025-12-01T06:48:55.395620Z","shell.execute_reply":"2025-12-01T06:48:55.407377Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndf.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2025-12-01T06:48:55.408619Z","iopub.execute_input":"2025-12-01T06:48:55.408912Z","iopub.status.idle":"2025-12-01T06:48:55.533060Z","shell.execute_reply.started":"2025-12-01T06:48:55.408888Z","shell.execute_reply":"2025-12-01T06:48:55.532463Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"\nWe drop the NaN values and have 4 helper functions to clean the data. These are:\n1. basic_cleaning - to remove website urls, non-characters and to replace '*****' swear words with the word swear\n2. remove_html\n3. remove_emojis\n4. remove_multiplechars - this is for when there are more than 3 characters in a row in a word e.g. wayyyyy. The function removes all but one of the letters\n\nThe data is then ready for initial exploration.","metadata":{}},{"cell_type":"code","source":"df.dropna(inplace=True)\n\ndf_clean = clean(df)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.535011Z","iopub.execute_input":"2025-12-01T06:48:55.535260Z","iopub.status.idle":"2025-12-01T06:48:55.868747Z","shell.execute_reply.started":"2025-12-01T06:48:55.535245Z","shell.execute_reply":"2025-12-01T06:48:55.868123Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"For the labels, one-hot encoding performed significantly better than LabelEncoder. We also tokenize and covert to sequences. ","metadata":{}},{"cell_type":"code","source":"df_clean_selection = df_clean.sample(frac=1)\nX = df_clean_selection.text.values\ny = pd.get_dummies(df_clean_selection.sentiment)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.869401Z","iopub.execute_input":"2025-12-01T06:48:55.869642Z","iopub.status.idle":"2025-12-01T06:48:55.885012Z","shell.execute_reply.started":"2025-12-01T06:48:55.869615Z","shell.execute_reply":"2025-12-01T06:48:55.884519Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=20000)\ntokenizer.fit_on_texts(list(X))\nlist_tokenized_train = tokenizer.texts_to_sequences(X)\nX_t = sequence.pad_sequences(list_tokenized_train, maxlen=128)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:55.885638Z","iopub.execute_input":"2025-12-01T06:48:55.885875Z","iopub.status.idle":"2025-12-01T06:48:56.539241Z","shell.execute_reply.started":"2025-12-01T06:48:55.885854Z","shell.execute_reply":"2025-12-01T06:48:56.538658Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# The model: DistilBert","metadata":{}},{"cell_type":"markdown","source":"We now turn our attention to pretrained embeddings. In this case we download and use DistilBert instead of training our own Embedding layer. DistilBert, a light version of BERT, google's game-changing NLP model, provides us with a tokenizer and an embedding matrix. BERT base uncased is trained on lower case English text and has around 110 million parameters (768 dimensions for embedding each word, and a vocab of 143,000 words). Distilbert has 60% of this, but maintains 97% performance against BERT. \n\nFor the purposes of this example, we will leave that matrix rather than train it, as it's large and we would have unrealistic training times. ","metadata":{}},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")  ## change it to commit\n\n# Save the loaded tokenizer locally\nsave_path = '/kaggle/working/distilbert_base_uncased/'\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\ntokenizer.save_pretrained(save_path)\n\n# Reload it with the huggingface tokenizers library\nfast_tokenizer = BertWordPieceTokenizer('distilbert_base_uncased/vocab.txt', lowercase=True)\nfast_tokenizer","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:56.540014Z","iopub.execute_input":"2025-12-01T06:48:56.540426Z","iopub.status.idle":"2025-12-01T06:48:58.136160Z","shell.execute_reply.started":"2025-12-01T06:48:56.540405Z","shell.execute_reply":"2025-12-01T06:48:58.135401Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"282d291b36ef46af81c266b3ed99697a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81fb91314cda4e98b267929ba115fae7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69b861b0fe1241e1ad11f5b9618ef0f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4571a7061440ed8fe4d1cba7f3ed2d"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Tokenizer(vocabulary_size=30522, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=None, lowercase=True, wordpieces_prefix=##)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"X = fast_encode(df_clean_selection.text.astype(str), fast_tokenizer, maxlen=128)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:58.137026Z","iopub.execute_input":"2025-12-01T06:48:58.137272Z","iopub.status.idle":"2025-12-01T06:48:59.221459Z","shell.execute_reply.started":"2025-12-01T06:48:58.137256Z","shell.execute_reply":"2025-12-01T06:48:59.220707Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(27480, 128)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:48:59.222317Z","iopub.execute_input":"2025-12-01T06:48:59.222691Z","iopub.status.idle":"2025-12-01T06:49:02.828380Z","shell.execute_reply.started":"2025-12-01T06:48:59.222666Z","shell.execute_reply":"2025-12-01T06:49:02.827837Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01e83245271c4a3c9bd69ff7145e1313"}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1764571742.044243      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nTensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFDistilBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"embedding_size = 128\ninput_ = Input(shape=(100,))\n\ninp = Input(shape=(128, ))\n#inp2= Input(shape=(1,))\n\nembedding_matrix=transformer_layer.weights[0].numpy()\n\nx = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],embeddings_initializer=Constant(embedding_matrix),trainable=False)(inp)\nx = Bidirectional(LSTM(50, return_sequences=True))(x)\nx = Bidirectional(LSTM(25, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dropout(0.5)(x)\nx = Dense(50, activation='relu', kernel_regularizer='L1L2')(x)\nx = Dropout(0.5)(x)\nx = Dense(3, activation='softmax')(x)\n\nmodel_DistilBert = Model(inputs=[inp], outputs=x)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:49:02.829051Z","iopub.execute_input":"2025-12-01T06:49:02.829298Z","iopub.status.idle":"2025-12-01T06:49:04.342719Z","shell.execute_reply.started":"2025-12-01T06:49:02.829271Z","shell.execute_reply":"2025-12-01T06:49:04.342113Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model_DistilBert.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:49:04.343373Z","iopub.execute_input":"2025-12-01T06:49:04.343596Z","iopub.status.idle":"2025-12-01T06:49:04.355047Z","shell.execute_reply.started":"2025-12-01T06:49:04.343580Z","shell.execute_reply":"2025-12-01T06:49:04.354425Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model_DistilBert.summary()","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:49:04.355669Z","iopub.execute_input":"2025-12-01T06:49:04.355917Z","iopub.status.idle":"2025-12-01T06:49:04.386378Z","shell.execute_reply.started":"2025-12-01T06:49:04.355895Z","shell.execute_reply":"2025-12-01T06:49:04.385856Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │    \u001b[38;5;34m23,440,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │       \u001b[38;5;34m327,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │        \u001b[38;5;34m25,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m153\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,440,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,796,399\u001b[0m (90.78 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,796,399</span> (90.78 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m355,503\u001b[0m (1.36 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,503</span> (1.36 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,440,896\u001b[0m (89.42 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,440,896</span> (89.42 MB)\n</pre>\n"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# model_DistilBert.fit(X,y,batch_size=32,epochs=10,validation_split=0.1) \nmodel_DistilBert.fit(X,y,batch_size=32,epochs=1,validation_split=0.1) ","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:49:04.387118Z","iopub.execute_input":"2025-12-01T06:49:04.387728Z","iopub.status.idle":"2025-12-01T06:49:36.405928Z","shell.execute_reply.started":"2025-12-01T06:49:04.387710Z","shell.execute_reply":"2025-12-01T06:49:36.405302Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_1']\nReceived: inputs=Tensor(shape=(None, 128))\n  warnings.warn(msg)\nI0000 00:00:1764571750.314331     155 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m773/773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4071 - loss: 1.0822","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_1']\nReceived: inputs=Tensor(shape=(None, 128))\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m773/773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.4072 - loss: 1.0821 - val_accuracy: 0.5932 - val_loss: 0.8593\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7baf4f48c4d0>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"df_clean_final = df_clean.sample(frac=1)\nX_train = fast_encode(df_clean_selection.text.astype(str), fast_tokenizer, maxlen=128)\ny_train = y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:49:36.406721Z","iopub.execute_input":"2025-12-01T06:49:36.407402Z","iopub.status.idle":"2025-12-01T06:49:37.502070Z","shell.execute_reply.started":"2025-12-01T06:49:36.407383Z","shell.execute_reply":"2025-12-01T06:49:37.501452Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"optimizer = Adam(learning_rate=0.001)\nmodel_DistilBert.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\nhistory = model_DistilBert.fit(X_train,y_train,batch_size=32,epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:49:37.502912Z","iopub.execute_input":"2025-12-01T06:49:37.503471Z","iopub.status.idle":"2025-12-01T06:53:55.299869Z","shell.execute_reply.started":"2025-12-01T06:49:37.503443Z","shell.execute_reply":"2025-12-01T06:53:55.299260Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_1']\nReceived: inputs=Tensor(shape=(None, 128))\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 29ms/step - accuracy: 0.6476 - loss: 0.7955\nEpoch 2/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.7327 - loss: 0.6625\nEpoch 3/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.7439 - loss: 0.6272\nEpoch 4/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.7614 - loss: 0.5978\nEpoch 5/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.7704 - loss: 0.5766\nEpoch 6/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - accuracy: 0.7734 - loss: 0.5683\nEpoch 7/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 30ms/step - accuracy: 0.7883 - loss: 0.5542\nEpoch 8/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.7931 - loss: 0.5232\nEpoch 9/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.8019 - loss: 0.5095\nEpoch 10/10\n\u001b[1m859/859\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.8076 - loss: 0.4891\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ndf_test.dropna(inplace=True)\ndf_clean_test = clean(df_test)\n\nX_test = fast_encode(df_clean_test.text.values.astype(str), fast_tokenizer, maxlen=128)\ny_test = df_clean_test.sentiment","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:53:55.300885Z","iopub.execute_input":"2025-12-01T06:53:55.301102Z","iopub.status.idle":"2025-12-01T06:53:55.507608Z","shell.execute_reply.started":"2025-12-01T06:53:55.301084Z","shell.execute_reply":"2025-12-01T06:53:55.506791Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"y_preds = model_DistilBert.predict(X_test)\ny_predictions = pd.DataFrame(y_preds, columns=['negative','neutral','positive'])\ny_predictions_final = y_predictions.idxmax(axis=1)\naccuracy = accuracy_score(y_test,y_predictions_final)\nprint(f\"The final model shows {accuracy:.2f} accuracy on the test set.\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:53:55.508429Z","iopub.execute_input":"2025-12-01T06:53:55.508733Z","iopub.status.idle":"2025-12-01T06:53:57.898726Z","shell.execute_reply.started":"2025-12-01T06:53:55.508712Z","shell.execute_reply":"2025-12-01T06:53:57.898008Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_1']\nReceived: inputs=Tensor(shape=(32, 128))\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m106/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_1']\nReceived: inputs=Tensor(shape=(None, 128))\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\nThe final model shows 0.77 accuracy on the test set.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"display = df_clean_test.copy()\ny_predictions.columns = ['predicted_' + f for f in y_predictions.columns]\npd.concat([display, y_predictions], axis = 1).head(10)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T06:53:57.899560Z","iopub.execute_input":"2025-12-01T06:53:57.900064Z","iopub.status.idle":"2025-12-01T06:53:57.912110Z","shell.execute_reply.started":"2025-12-01T06:53:57.900039Z","shell.execute_reply":"2025-12-01T06:53:57.911358Z"},"trusted":true},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"       textID                                               text sentiment  \\\n0  f87dea47db         Last session of the day  httptwitpiccomezh   neutral   \n1  96d74cb729   Shanghai is also really exciting precisely  s...  positive   \n2  eee518ae67  Recession hit Veronique Branquinho she has to ...  negative   \n3  01082688c6                                         happy bday  positive   \n4  33987a8ee5                        httptwitpiccomwp  I like it  positive   \n5  726e501993                          thats great weee visitors  positive   \n6  261932614e            I THINK EVERYONE HATES ME ON HERE   lol  negative   \n7  afa11da83f   so wish i could but im in school and myspace ...  negative   \n8  e64208b4ef   and within a short time of the last clue all ...   neutral   \n9  37bcad24ca   What did you get  My day is alright havent do...   neutral   \n\n   predicted_negative  predicted_neutral  predicted_positive  \n0            0.017783           0.977263            0.004953  \n1            0.000009           0.007522            0.992469  \n2            0.982314           0.017628            0.000058  \n3            0.000011           0.005931            0.994058  \n4            0.002239           0.066216            0.931546  \n5            0.000040           0.014379            0.985581  \n6            0.931767           0.067080            0.001153  \n7            0.801600           0.188866            0.009533  \n8            0.039658           0.945066            0.015276  \n9            0.149223           0.819487            0.031290  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>predicted_negative</th>\n      <th>predicted_neutral</th>\n      <th>predicted_positive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  httptwitpiccomezh</td>\n      <td>neutral</td>\n      <td>0.017783</td>\n      <td>0.977263</td>\n      <td>0.004953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>Shanghai is also really exciting precisely  s...</td>\n      <td>positive</td>\n      <td>0.000009</td>\n      <td>0.007522</td>\n      <td>0.992469</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>Recession hit Veronique Branquinho she has to ...</td>\n      <td>negative</td>\n      <td>0.982314</td>\n      <td>0.017628</td>\n      <td>0.000058</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday</td>\n      <td>positive</td>\n      <td>0.000011</td>\n      <td>0.005931</td>\n      <td>0.994058</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>httptwitpiccomwp  I like it</td>\n      <td>positive</td>\n      <td>0.002239</td>\n      <td>0.066216</td>\n      <td>0.931546</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>726e501993</td>\n      <td>thats great weee visitors</td>\n      <td>positive</td>\n      <td>0.000040</td>\n      <td>0.014379</td>\n      <td>0.985581</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>261932614e</td>\n      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n      <td>negative</td>\n      <td>0.931767</td>\n      <td>0.067080</td>\n      <td>0.001153</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>afa11da83f</td>\n      <td>so wish i could but im in school and myspace ...</td>\n      <td>negative</td>\n      <td>0.801600</td>\n      <td>0.188866</td>\n      <td>0.009533</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>e64208b4ef</td>\n      <td>and within a short time of the last clue all ...</td>\n      <td>neutral</td>\n      <td>0.039658</td>\n      <td>0.945066</td>\n      <td>0.015276</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>37bcad24ca</td>\n      <td>What did you get  My day is alright havent do...</td>\n      <td>neutral</td>\n      <td>0.149223</td>\n      <td>0.819487</td>\n      <td>0.031290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21}]}